# Taller NLP


## ACTIVIDAD:

Crear sistema de web scraping, y crear dataset de al menos 5 categorías , con datos obtenidos a través del web scraping.
- Las categorías deben de estar numéricamente balanceadas en cantidad.
- Se debe crear un procedimiento automatizado de preprocesamiento .
- Se debe desarrollar un modelo de redes neuronales artificiales con tensor flow/keras , para el procesamiento de este dataset.
- Se debe crear una api rest , que proporcione por medio de métodos http , un ingreso de datos y una salida de la clasificación del mismo.


## Requerimientos
- Instalar Python https://www.python.org/
- Instalar Git https://git-scm.com/
- Instalar visual estudio code https://code.visualstudio.com/

## Pasos sugeridos para iniciar proyecto clonado

- Crear carpeta    mkdir tallernlp
- Ir a carpeta
- Clonar Repositorio git clone https://github.com/centrograduadosFIUBA/tallernlp
- Abrir visual estudio code  con code .
- Crear entorno Python -m venv env
- Agregar entorno a gitignore
- Instalar dependencias con pip install -r requirements.txt

## Pasos sugeridos para iniciar proyecto desde cero

- Crear carpeta    mkdir tallernlp
- Ir a carpeta
- Agregar los archivos del Repositorio git ( https://github.com/centrograduadosFIUBA/tallernlp)
- Abrir visual estudio code  con code .
- Inicializar proyecto con git init
- Crear gitignore
- Crear entorno Python -m venv env
- Agregar entorno a gitignore
- Crear requirements.txt
- Instalar dependencias con pip install -r requirements.txt
